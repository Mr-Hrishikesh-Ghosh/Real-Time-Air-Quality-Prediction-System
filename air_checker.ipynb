{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgHohiiaqVY3dX6YlCo1fN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mr-Hrishikesh-Ghosh/Real-Time-Air-Quality-Prediction-System/blob/main/air_checker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "dYzYThsRX3wY",
        "outputId": "a3921b67-57d0-4683-c22b-5edcc1dba383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Launching Real-Time Air Quality Prediction System...\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7866, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# real_time_air_quality_predictor_fixed.py\n",
        "# Run in Google Colab or locally.\n",
        "# Requirements:\n",
        "# pip install pandas numpy scikit-learn requests joblib matplotlib gradio python-dateutil\n",
        "\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "import joblib\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from dateutil import parser\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import gradio as gr\n",
        "\n",
        "# -------------------------\n",
        "# Configuration & Cities\n",
        "# -------------------------\n",
        "CITIES = [\n",
        "    \"New Delhi\", \"Mumbai\", \"Kolkata\", \"Chennai\", \"Bengaluru\",\n",
        "    \"Hyderabad\", \"Ahmedabad\", \"Pune\", \"Lucknow\", \"Jaipur\"\n",
        "]\n",
        "POLLUTANTS = [\"pm25\", \"pm10\", \"o3\", \"co\", \"so2\", \"no2\"]\n",
        "\n",
        "OPENAQ_MEASUREMENTS = \"https://api.openaq.org/v2/measurements\"\n",
        "MODEL_DIR = \"aq_models\"\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# -------------------------\n",
        "# Data fetching\n",
        "# -------------------------\n",
        "def fetch_openaq_city_measurements(city, days=7, limit=10000):\n",
        "    to_date = datetime.utcnow()\n",
        "    from_date = to_date - timedelta(days=days)\n",
        "    params = {\n",
        "        \"city\": city,\n",
        "        \"date_from\": from_date.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
        "        \"date_to\": to_date.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
        "        \"limit\": 10000,\n",
        "        \"page\": 1,\n",
        "        \"sort\": \"desc\",\n",
        "        \"order_by\": \"datetime\"\n",
        "    }\n",
        "    all_results = []\n",
        "    try:\n",
        "        while True:\n",
        "            resp = requests.get(OPENAQ_MEASUREMENTS, params=params, timeout=15)\n",
        "            resp.raise_for_status()\n",
        "            j = resp.json()\n",
        "            results = j.get(\"results\", [])\n",
        "            if not results:\n",
        "                break\n",
        "            all_results.extend(results)\n",
        "            meta = j.get(\"meta\", {})\n",
        "            found = meta.get(\"found\", 0)\n",
        "            per_page = meta.get(\"limit\", len(results))\n",
        "            if len(all_results) >= min(found, limit):\n",
        "                break\n",
        "            params[\"page\"] += 1\n",
        "            time.sleep(0.2)\n",
        "            if params[\"page\"] > 10:\n",
        "                break\n",
        "    except Exception as e:\n",
        "        print(f\"[fetch_openaq_city_measurements] error for {city}: {e}\")\n",
        "        return None\n",
        "\n",
        "    if not all_results:\n",
        "        return None\n",
        "\n",
        "    rows = []\n",
        "    for r in all_results:\n",
        "        dt = r.get(\"date\", {}).get(\"utc\") or r.get(\"date\", {}).get(\"local\")\n",
        "        try:\n",
        "            dt = parser.isoparse(dt)\n",
        "        except Exception:\n",
        "            continue\n",
        "        rows.append({\n",
        "            \"datetime\": dt,\n",
        "            \"parameter\": r.get(\"parameter\"),\n",
        "            \"value\": r.get(\"value\"),\n",
        "            \"unit\": r.get(\"unit\")\n",
        "        })\n",
        "    if not rows:\n",
        "        return None\n",
        "    df = pd.DataFrame(rows)\n",
        "    return df\n",
        "\n",
        "def pivot_and_hourly_average(df):\n",
        "    if df is None or df.empty:\n",
        "        return None\n",
        "    df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
        "    df[\"datetime_hour\"] = df[\"datetime\"].dt.floor(\"H\")\n",
        "    df = df[df[\"parameter\"].isin(POLLUTANTS)].copy()\n",
        "    if df.empty:\n",
        "        return None\n",
        "    pivot = df.groupby([\"datetime_hour\", \"parameter\"])[\"value\"].mean().unstack(level=-1)\n",
        "    for p in POLLUTANTS:\n",
        "        if p not in pivot.columns:\n",
        "            pivot[p] = np.nan\n",
        "    pivot = pivot.sort_index()\n",
        "    idx = pd.date_range(start=pivot.index.min(), end=pivot.index.max(), freq=\"H\")\n",
        "    pivot = pivot.reindex(idx)\n",
        "    pivot = pivot.ffill(limit=3).bfill(limit=3)\n",
        "    return pivot\n",
        "\n",
        "# -------------------------\n",
        "# Synthetic fallback\n",
        "# -------------------------\n",
        "def generate_synthetic_series(days=7, freq=\"H\", seed=42, base_values=None):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    idx = pd.date_range(end=datetime.utcnow(), periods=int(days*24), freq=freq)\n",
        "    df = pd.DataFrame(index=idx)\n",
        "    if base_values is None:\n",
        "        base_values = {\"pm25\": 60, \"pm10\": 100, \"o3\": 30, \"co\": 0.7, \"so2\": 10, \"no2\": 40}\n",
        "    for p in POLLUTANTS:\n",
        "        hours = np.arange(len(idx))\n",
        "        daily = 1 + 0.2 * np.sin(2 * math.pi * (hours % 24) / 24.0)\n",
        "        weekly = 1 + 0.05 * np.sin(2 * math.pi * (hours % (24*7)) / (24*7))\n",
        "        noise = rng.normal(scale=0.1 * base_values[p], size=len(idx))\n",
        "        df[p] = np.maximum(0.0, base_values[p] * daily * weekly + noise)\n",
        "    return df\n",
        "\n",
        "# -------------------------\n",
        "# Feature engineering\n",
        "# -------------------------\n",
        "def create_features(df):\n",
        "    df_feat = df.copy()\n",
        "    df_feat[\"hour\"] = df_feat.index.hour\n",
        "    df_feat[\"dayofweek\"] = df_feat.index.dayofweek\n",
        "    for p in POLLUTANTS:\n",
        "        df_feat[f\"{p}_lag1\"] = df_feat[p].shift(1)\n",
        "        df_feat[f\"{p}_lag2\"] = df_feat[p].shift(2)\n",
        "        df_feat[f\"{p}_roll3\"] = df_feat[p].rolling(3, min_periods=1).mean()\n",
        "        df_feat[f\"{p}_roll24\"] = df_feat[p].rolling(24, min_periods=1).mean()\n",
        "    y = {p: df_feat[p].shift(-1) for p in POLLUTANTS}\n",
        "    combined = df_feat.copy()\n",
        "    for p in POLLUTANTS:\n",
        "        combined[f\"{p}_target\"] = y[p]\n",
        "    combined = combined.dropna()\n",
        "    feature_cols = [\"hour\", \"dayofweek\"]\n",
        "    for p in POLLUTANTS:\n",
        "        feature_cols += [f\"{p}_lag1\", f\"{p}_lag2\", f\"{p}_roll3\", f\"{p}_roll24\"]\n",
        "    X = combined[feature_cols]\n",
        "    y_dict = {p: combined[f\"{p}_target\"] for p in POLLUTANTS}\n",
        "    return X, y_dict, combined.index\n",
        "\n",
        "# -------------------------\n",
        "# Training models\n",
        "# -------------------------\n",
        "def train_models_for_city(city, df_hourly, force_retrain=False):\n",
        "    models, metrics = {}, {}\n",
        "    if df_hourly is None or df_hourly.empty:\n",
        "        return models, metrics\n",
        "\n",
        "    X, y_dict, idx = create_features(df_hourly)\n",
        "    if X.empty:\n",
        "        return models, metrics\n",
        "\n",
        "    for p in POLLUTANTS:\n",
        "        model_path = os.path.join(MODEL_DIR, f\"{city.replace(' ', '_')}_{p}.joblib\")\n",
        "        if os.path.exists(model_path) and not force_retrain:\n",
        "            try:\n",
        "                models[p] = joblib.load(model_path)\n",
        "                metrics[p] = None\n",
        "                continue\n",
        "            except Exception:\n",
        "                pass\n",
        "        y = y_dict[p]\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
        "        rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=1)\n",
        "        rf.fit(X_train, y_train)\n",
        "        y_pred = rf.predict(X_test)\n",
        "        rmse = math.sqrt(mean_squared_error(y_test, y_pred))\n",
        "        models[p] = rf\n",
        "        metrics[p] = rmse\n",
        "        try:\n",
        "            joblib.dump(rf, model_path)\n",
        "        except Exception:\n",
        "            pass\n",
        "    return models, metrics\n",
        "\n",
        "# -------------------------\n",
        "# Prediction\n",
        "# -------------------------\n",
        "def load_models_if_exist(city):\n",
        "    models = {}\n",
        "    for p in POLLUTANTS:\n",
        "        path = os.path.join(MODEL_DIR, f\"{city.replace(' ', '_')}_{p}.joblib\")\n",
        "        if os.path.exists(path):\n",
        "            try:\n",
        "                models[p] = joblib.load(path)\n",
        "            except Exception:\n",
        "                models[p] = None\n",
        "        else:\n",
        "            models[p] = None\n",
        "    return models\n",
        "\n",
        "def make_prediction_for_city(city, df_hourly, models=None):\n",
        "    if df_hourly is None or df_hourly.empty:\n",
        "        return None, None\n",
        "    if models is None:\n",
        "        models = load_models_if_exist(city)\n",
        "    missing = [p for p in POLLUTANTS if models.get(p) is None]\n",
        "    if missing:\n",
        "        trained, metrics = train_models_for_city(city, df_hourly, force_retrain=False)\n",
        "        for p in trained:\n",
        "            models[p] = trained[p]\n",
        "    X, y_dict, idx = create_features(df_hourly)\n",
        "    if X.empty:\n",
        "        last = df_hourly.iloc[-1]\n",
        "        feature_row = {\"hour\": last.name.hour, \"dayofweek\": last.name.dayofweek}\n",
        "        for p in POLLUTANTS:\n",
        "            feature_row[f\"{p}_lag1\"] = df_hourly[p].iloc[-1]\n",
        "            feature_row[f\"{p}_lag2\"] = df_hourly[p].iloc[-2] if len(df_hourly) > 1 else df_hourly[p].iloc[-1]\n",
        "            feature_row[f\"{p}_roll3\"] = df_hourly[p].iloc[-3:].mean() if len(df_hourly) >= 3 else df_hourly[p].mean()\n",
        "            feature_row[f\"{p}_roll24\"] = df_hourly[p].iloc[-24:].mean() if len(df_hourly) >= 24 else df_hourly[p].mean()\n",
        "        X_latest = pd.DataFrame([feature_row])\n",
        "    else:\n",
        "        X_latest = X.tail(1)\n",
        "\n",
        "    preds = {}\n",
        "    for p in POLLUTANTS:\n",
        "        model = models.get(p)\n",
        "        if model is None:\n",
        "            preds[p] = float(df_hourly[p].iloc[-1])\n",
        "        else:\n",
        "            try:\n",
        "                pred = model.predict(X_latest)[0]\n",
        "                preds[p] = float(max(0.0, pred))\n",
        "            except Exception:\n",
        "                preds[p] = float(df_hourly[p].iloc[-1])\n",
        "    return preds, df_hourly\n",
        "\n",
        "# -------------------------\n",
        "# Health advice\n",
        "# -------------------------\n",
        "def simple_health_advice(preds):\n",
        "    pm25 = preds.get(\"pm25\", None)\n",
        "    if pm25 is None:\n",
        "        return \"No prediction available.\"\n",
        "    if pm25 <= 12:\n",
        "        return \"Good — Everyone can go outside as usual.\"\n",
        "    elif pm25 <= 35.4:\n",
        "        return \"Moderate — Sensitive groups should reduce prolonged outdoor exertion.\"\n",
        "    elif pm25 <= 55.4:\n",
        "        return \"Unhealthy for sensitive groups — Respiratory patients should be careful.\"\n",
        "    elif pm25 <= 150.4:\n",
        "        return \"Unhealthy — Older adults and children should avoid prolonged outdoor exertion.\"\n",
        "    else:\n",
        "        return \"Very Unhealthy/Hazardous — Everyone should reduce outdoor exposure.\"\n",
        "\n",
        "# -------------------------\n",
        "# Plotting\n",
        "# -------------------------\n",
        "def plot_history(df_hourly, pollutant_list=None, hours=24):\n",
        "    if df_hourly is None or df_hourly.empty:\n",
        "        fig, ax = plt.subplots(figsize=(8,3))\n",
        "        ax.text(0.5, 0.5, \"No historical data available\", ha=\"center\", va=\"center\")\n",
        "        ax.axis(\"off\")\n",
        "        return fig\n",
        "    sub = df_hourly.copy().tail(hours)\n",
        "    if pollutant_list is None:\n",
        "        pollutant_list = POLLUTANTS\n",
        "    fig, ax = plt.subplots(figsize=(9,4))\n",
        "    for p in pollutant_list:\n",
        "        if p in sub.columns:\n",
        "            ax.plot(sub.index, sub[p], label=p.upper())\n",
        "    ax.set_title(f\"Past {hours} hours pollutant history\")\n",
        "    ax.set_xlabel(\"Time (UTC)\")\n",
        "    ax.set_ylabel(\"Concentration\")\n",
        "    ax.legend()\n",
        "    fig.tight_layout()\n",
        "    return fig\n",
        "\n",
        "# -------------------------\n",
        "# Data preparation\n",
        "# -------------------------\n",
        "def prepare_city_data(city, days=7, fallback_bases=None):\n",
        "    df_raw = fetch_openaq_city_measurements(city, days=days)\n",
        "    df_hourly = pivot_and_hourly_average(df_raw)\n",
        "    if df_hourly is None or df_hourly.isna().all().all():\n",
        "        df_hourly = generate_synthetic_series(days=days, base_values=fallback_bases.get(city) if fallback_bases else None)\n",
        "    for p in POLLUTANTS:\n",
        "        if p not in df_hourly.columns:\n",
        "            df_hourly[p] = np.nan\n",
        "    df_hourly = df_hourly.ffill(limit=3).bfill(limit=3)\n",
        "    return df_hourly\n",
        "\n",
        "# -------------------------\n",
        "# Gradio UI\n",
        "# -------------------------\n",
        "def gradio_interface():\n",
        "    def predict_ui(city, history_hours):\n",
        "        df_city = prepare_city_data(city, days=7)\n",
        "        preds, df_hourly = make_prediction_for_city(city, df_city)\n",
        "        if preds is None:\n",
        "            return [], \"No data available\", None\n",
        "        table = pd.DataFrame({\n",
        "            \"Pollutant\": [p.upper() for p in POLLUTANTS],\n",
        "            \"Predicted\": [round(preds[p], 3) for p in POLLUTANTS]\n",
        "        })\n",
        "        advice = simple_health_advice(preds)\n",
        "        fig = plot_history(df_hourly, pollutant_list=POLLUTANTS, hours=history_hours)\n",
        "        return table.values.tolist(), advice, fig\n",
        "\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# Real-Time Air Quality Prediction System\")\n",
        "        gr.Markdown(\"Select a city and get predicted pollutant levels, health advice, and a historical chart.\")\n",
        "        with gr.Row():\n",
        "            city_sel = gr.Dropdown(choices=CITIES, value=CITIES[0], label=\"City\")\n",
        "            hours_sel = gr.Slider(minimum=6, maximum=168, step=6, value=48, label=\"History (hours)\")\n",
        "            run_btn = gr.Button(\"Get Prediction\")\n",
        "        with gr.Row():\n",
        "            table_out = gr.Dataframe(headers=[\"Pollutant\",\"Predicted\"], label=\"Predicted next-hour values\")\n",
        "        with gr.Row():\n",
        "            advice_out = gr.Textbox(label=\"Health Advice\")\n",
        "        with gr.Row():\n",
        "            plot_out = gr.Plot(label=\"Historical Chart\")\n",
        "        run_btn.click(fn=predict_ui, inputs=[city_sel, hours_sel], outputs=[table_out, advice_out, plot_out])\n",
        "    return demo\n",
        "\n",
        "# -------------------------\n",
        "# Main\n",
        "# -------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Launching Real-Time Air Quality Prediction System...\")\n",
        "    demo = gradio_interface()\n",
        "    demo.launch(share=False)\n"
      ]
    }
  ]
}