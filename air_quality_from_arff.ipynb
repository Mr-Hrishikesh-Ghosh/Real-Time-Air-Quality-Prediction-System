{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# City Day Data Analysis from Zip File\n",
    "\n",
    "This notebook is designed to automatically load and process a .zip file containing air quality data. It includes steps for:\n",
    "\n",
    "1.  Data Loading: Extracts a CSV file from a zip archive and loads it into a Pandas DataFrame.\n",
    "2.  Exploratory Data Analysis (EDA): Provides a quick overview of the data, including a description, and checks for missing values.\n",
    "3.  Preprocessing & Model Training: Sets up a machine learning pipeline to handle both numeric and categorical features and trains a baseline RandomForest model.\n",
    "4.  Evaluation: Reports key metrics to assess the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Imports & Setup ---\n",
    "import os, zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "# Path to the ZIP file and contained CSV\n",
    "ZIP_PATH = r\"/mnt/data/archive (1).zip\"\n",
    "CSV_FILE_NAME = \"city_day.csv\"\n",
    "TARGET_FALLBACK = \"AQI_Bucket\"  # target for classification\n",
    "\n",
    "print(\"Zip file path:\", ZIP_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Data Loading and Extraction ---\n",
    "def load_csv_from_zip(zip_path, file_name):\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extract(file_name, \".\")\n",
    "        df = pd.read_csv(file_name)\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{zip_path}' or '{file_name}' was not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading the data: {e}\")\n",
    "        return None\n",
    "\n",
    "df = load_csv_from_zip(ZIP_PATH, CSV_FILE_NAME)\n",
    "if df is not None:\n",
    "    print(\"Shape:\", df.shape)\n",
    "    print(\"Columns (first 10):\", list(df.columns)[:10], \"...\" if df.shape[1] > 10 else \"\")\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"Could not load data. Please check the file path and name.\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Exploratory Data Analysis (EDA) ---\n",
    "if df is None:\n",
    "    raise ValueError(\"DataFrame is empty, cannot proceed with analysis.\")\n",
    "\n",
    "cols_lower = {c.lower(): c for c in df.columns}\n",
    "if TARGET_FALLBACK and TARGET_FALLBACK in df.columns:\n",
    "    target_col = TARGET_FALLBACK\n",
    "elif \"class\" in cols_lower:\n",
    "    target_col = cols_lower[\"class\"]\n",
    "else:\n",
    "    target_col = df.columns[-1] if len(df.columns) else None\n",
    "\n",
    "print(\"Target column selected:\", target_col)\n",
    "\n",
    "display(df.describe(include=\"all\"))\n",
    "print(\"Missing values (top 20):\")\n",
    "print(df.isna().sum().sort_values(ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Data Splitting and Model Training ---\n",
    "if target_col is None:\n",
    "    raise ValueError(\"Could not determine a target column. Please set target_col manually.\")\n",
    "\n",
    "X = df.drop(columns=[target_col]).copy()\n",
    "y = df[target_col].copy()\n",
    "\n",
    "is_numeric_target = pd.api.types.is_numeric_dtype(y)\n",
    "n_unique = y.nunique(dropna=True)\n",
    "task = \"classification\"\n",
    "if is_numeric_target and n_unique > 15:\n",
    "    task = \"regression\"\n",
    "print(f\"Detected task: {task} (unique target values: {n_unique})\")\n",
    "\n",
    "valid_indices = y.dropna().index\n",
    "X = X.loc[valid_indices]\n",
    "y = y.loc[valid_indices]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42,\n",
    "    stratify=y if task==\"classification\" and n_unique>1 else None\n",
    ")\n",
    "\n",
    "num_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]\n",
    "cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(with_mean=False), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "if task == \"classification\":\n",
    "    model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "else:\n",
    "    model = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "\n",
    "pipe = Pipeline(steps=[(\"prep\", preprocess), (\"model\", model)])\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Model Evaluation ---\n",
    "if task == \"classification\":\n",
    "    pred = pipe.predict(X_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, pred))\n",
    "    print(\"F1 (macro):\", f1_score(y_test, pred, average=\"macro\"))\n",
    "    print(\"\\nClassification report:\\n\", classification_report(y_test, pred))\n",
    "else:\n",
    "    pred = pipe.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, pred, squared=False)\n",
    "    r2 = r2_score(y_test, pred)\n",
    "    print(\"RMSE:\", rmse)\n",
    "    print(\"R^2:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. (Optional) Permutation Importance ---\n",
    "try:\n",
    "    from sklearn.inspection import permutation_importance\n",
    "    r = permutation_importance(pipe, X_test, y_test, n_repeats=5, random_state=42)\n",
    "    cat_encoder = pipe.named_steps[\"prep\"].transformers_[1][1]\n",
    "    cat_feature_names = list(cat_encoder.get_feature_names_out(cat_cols)) if len(cat_cols) else []\n",
    "    feature_names = num_cols + cat_feature_names\n",
    "    importances = pd.Series(r.importances_mean, index=feature_names)\n",
    "    display(importances.sort_values(ascending=False).head(20))\n",
    "except Exception as e:\n",
    "    print(\"Permutation importance skipped. Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Save a Raw CSV Copy ---\n",
    "clean_csv_path = \"/mnt/data/city_day_raw.csv\"\n",
    "if df is not None:\n",
    "    df.to_csv(clean_csv_path, index=False)\n",
    "    print(\"Saved raw CSV to:\", clean_csv_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
