{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f461878",
   "metadata": {},
   "source": [
    "# Auto Notebook for ARFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ff46b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports & Setup\n",
    "import os, re, io, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    from scipy.io import arff as scipy_arff\n",
    "    HAVE_SCIPY = True\n",
    "except Exception as e:\n",
    "    HAVE_SCIPY = False\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "DATA_PATH = r\"/mnt/data/air_quality_realtime_large (1).arff\"\n",
    "TARGET_FALLBACK = None  # set a column name here to override\n",
    "print(\"Data path:\", DATA_PATH)\n",
    "print(\"SciPy available:\", HAVE_SCIPY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc40d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hello from notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d87f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_arff_lightweight(text):\n",
    "    \"\"\"\n",
    "    Very lightweight ARFF parser that handles:\n",
    "      - % comments\n",
    "      - @relation\n",
    "      - @attribute name type\n",
    "      - @data (CSV-like rows)\n",
    "    Nominal attributes like {a,b,c} are treated as 'category' dtype later.\n",
    "    Returns (df, attributes), where attributes is list of (name, type_str).\n",
    "    \"\"\"\n",
    "    import re\n",
    "    lines = [ln.strip() for ln in text.splitlines()]\n",
    "    attrs = []\n",
    "    data_lines = []\n",
    "    in_data = False\n",
    "    for ln in lines:\n",
    "        if not ln or ln.startswith('%'):\n",
    "            continue\n",
    "        low = ln.lower()\n",
    "        if low.startswith('@relation'):\n",
    "            continue\n",
    "        if low.startswith('@attribute'):\n",
    "            m = re.match(r\"(?i)@attribute\\s+'?([^'\\s]+[^']?)'?\\s+(.+)\", ln)\n",
    "            if m:\n",
    "                name = m.group(1)\n",
    "                typ = m.group(2).strip()\n",
    "                attrs.append((name, typ))\n",
    "            continue\n",
    "        if low.startswith('@data'):\n",
    "            in_data = True\n",
    "            continue\n",
    "        if in_data:\n",
    "            if ln:\n",
    "                data_lines.append(ln)\n",
    "\n",
    "    rows = []\n",
    "    for dl in data_lines:\n",
    "        parts = []\n",
    "        buff = ''\n",
    "        in_quote = False\n",
    "        i = 0\n",
    "        while i < len(dl):\n",
    "            ch = dl[i]\n",
    "            if ch == \"'\":\n",
    "                in_quote = not in_quote\n",
    "                buff += ch\n",
    "            elif ch == \",\" and not in_quote:\n",
    "                parts.append(buff.strip())\n",
    "                buff = ''\n",
    "            else:\n",
    "                buff += ch\n",
    "            i += 1\n",
    "        parts.append(buff.strip())\n",
    "        rows.append(parts)\n",
    "\n",
    "    colnames = [a[0] for a in attrs]\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    df = pd.DataFrame(rows, columns=colnames)\n",
    "\n",
    "    for c, (_, t) in zip(df.columns, attrs):\n",
    "        df[c] = df[c].replace(\"?\", np.nan)\n",
    "        df[c] = df[c].astype(str).str.strip()\n",
    "        df[c] = df[c].str.replace(r\"^'(.*)'$\", r\"\\1\", regex=True)\n",
    "        if re.match(r\"(?i)numeric|real|integer\", t):\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    return df, attrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfb44ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_arff_to_df(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    if 'scipy_arff' in globals() and HAVE_SCIPY:\n",
    "        try:\n",
    "            data, meta = scipy_arff.loadarff(io.StringIO(text))\n",
    "            df = pd.DataFrame(data)\n",
    "            for col in df.columns:\n",
    "                if df[col].dtype == object:\n",
    "                    df[col] = df[col].apply(lambda x: x.decode(\"utf-8\") if isinstance(x, (bytes, bytearray)) else x)\n",
    "            attrs = [(name, str(meta[name])) for name in df.columns]\n",
    "            return df, attrs\n",
    "        except Exception as e:\n",
    "            print(\"SciPy ARFF load failed, falling back. Error:\", e)\n",
    "\n",
    "    df, attrs = parse_arff_lightweight(text)\n",
    "    return df, attrs\n",
    "\n",
    "df, ATTRS = load_arff_to_df(DATA_PATH)\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns (first 10):\", list(df.columns)[:10], \"...\" if df.shape[1] > 10 else \"\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c154270a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Target detection and basic EDA\n",
    "cols_lower = {c.lower(): c for c in df.columns}\n",
    "if \"class\" in cols_lower:\n",
    "    target_col = cols_lower[\"class\"]\n",
    "else:\n",
    "    target_col = df.columns[-1] if len(df.columns) else None\n",
    "\n",
    "if TARGET_FALLBACK and TARGET_FALLBACK in df.columns:\n",
    "    target_col = TARGET_FALLBACK\n",
    "\n",
    "print(\"Target column selected:\", target_col)\n",
    "\n",
    "display(df.head(10))\n",
    "display(df.describe(include=\"all\"))\n",
    "print(\"Missing values (top 20):\")\n",
    "print(df.isna().sum().sort_values(ascending=False).head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dfaadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train/test split and baseline model\n",
    "import pandas as pd\n",
    "\n",
    "if target_col is None:\n",
    "    raise ValueError(\"Could not determine a target column. Please set `target_col` manually.\")\n",
    "\n",
    "X = df.drop(columns=[target_col]).copy()\n",
    "y = df[target_col].copy()\n",
    "\n",
    "is_numeric_target = pd.api.types.is_numeric_dtype(y)\n",
    "n_unique = y.nunique(dropna=True)\n",
    "task = \"classification\"\n",
    "if is_numeric_target and n_unique > 15:\n",
    "    task = \"regression\"\n",
    "print(f\"Detected task: {task} (unique target values: {n_unique})\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42,\n",
    "    stratify=y if task==\"classification\" and n_unique>1 else None\n",
    ")\n",
    "\n",
    "num_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]\n",
    "cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(with_mean=False), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "if task == \"classification\":\n",
    "    model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "else:\n",
    "    model = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "\n",
    "pipe = Pipeline(steps=[(\"prep\", preprocess), (\"model\", model)])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "if task == \"classification\":\n",
    "    pred = pipe.predict(X_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, pred))\n",
    "    print(\"F1 (macro):\", f1_score(y_test, pred, average=\"macro\"))\n",
    "    print(\"\\nClassification report:\\n\", classification_report(y_test, pred))\n",
    "else:\n",
    "    pred = pipe.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, pred, squared=False)\n",
    "    r2 = r2_score(y_test, pred)\n",
    "    print(\"RMSE:\", rmse)\n",
    "    print(\"R^2:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b40277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optional: permutation importance\n",
    "try:\n",
    "    from sklearn.inspection import permutation_importance\n",
    "    r = permutation_importance(pipe, X_test, y_test, n_repeats=5, random_state=42, scoring=None)\n",
    "    cat_encoder = pipe.named_steps[\"prep\"].transformers_[1][1]\n",
    "    cat_feature_names = list(cat_encoder.get_feature_names_out(cat_cols)) if len(cat_cols) else []\n",
    "    feature_names = num_cols + cat_feature_names\n",
    "    import pandas as pd\n",
    "    importances = pd.Series(r.importances_mean, index=feature_names)\n",
    "    display(importances.sort_values(ascending=False).head(20))\n",
    "except Exception as e:\n",
    "    print(\"Permutation importance skipped:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520557cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save a raw CSV copy (optional)\n",
    "clean_csv_path = \"/mnt/data/air_quality_from_arff_raw.csv\"\n",
    "df.to_csv(clean_csv_path, index=False)\n",
    "print(\"Saved raw CSV to:\", clean_csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97897a9d",
   "metadata": {},
   "source": [
    "## Next steps\\n- Adjust `target_col` if auto-detection isn't correct.\\n- Tune model hyperparameters.\\n- Add domain-specific feature engineering.\\n- Try cross-validation and additional algorithms.\\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
